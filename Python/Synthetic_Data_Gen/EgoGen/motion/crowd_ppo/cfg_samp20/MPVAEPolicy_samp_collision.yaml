cfg_name: MPVAEPolicy_samp_collision
wandb:
  enable: true
  entity: interaction
  project: interaction_motion
  group: collision_avoidance
  name: collision_test


modelconfig:
  h_dim: 512
  z_dim: 128 #this should be consistent with GAMMAcombo
  n_blocks: 2
  n_recur: -1
  body_repr: ssm2_67_condi_marker_map
  map_res: 16
  map_extent: 0.8
  map_dim: 256
  dump_map: false
  actfun: lrelu
  is_stochastic: true
  min_logvar: -2.5
  max_logvar: 2.5
  reproj_factor: 0.5

lossconfig:
  ppo_clip_val: 0.2
  reward_discount: 0.99
  gae_decay: 0.97
  kld_thresh: 0.02
  use_facing_reward: false
  use_vposer_reward: true
  use_normalized_movement: true
  use_slow_movement: false
  body_ori_weight: 0.5
  target_dist_weight: 1

  weight_contact_friction: 0
  weight_target: 0

  weight_vp: 0.1
  weight_floor: 0.1
  weight_skate: 0.3
  weight_smooth: 0
  weight_target_dist: 1
  weight_face_target: 0.1
  weight_look_target: 0.3 # 0.1
  # weight_move_toward: 0.5
  # kld_weight: 10 # set kld weight in main.py use args!
  weight_pene: 0.1 # pretrain: 1, finetune: 0.1. reduce reward to make it move to the goal
  pene_type: body
  weight_nonstatic: 0.1
  weight_success: 0.5
  sparse_reward: false

trainconfig:
  cfg_1frame_male: MPVAECombo_samp_1frame
  cfg_1frame_female: MPVAECombo_samp_1frame
  cfg_2frame_male: MPVAECombo_samp_2frame
  cfg_2frame_female: MPVAECombo_samp_2frame
  n_gens_1frame: 32
  n_gens_2frame: 1
  # num_envs_per_epoch: 8
  # batch_size: 1024
  learning_rate_p: 0.0003
  learning_rate_v: 0.0003
  max_train_iter_1f: 3
  max_train_iter_2f: 3
  num_epochs: 10000
  saving_per_X_ep: 100
  log_interval: 20
  resume_training: false

  clip_gradient: true
  max_norm: 0.1
  goal_disturb_sigma: 3
  random_rotation_range: 1
  goal_thresh: 0.1
  use_early_stop: true
  max_depth: 13 # 15
  pene_thres: 3

args:
  gpu_index: 0
  random_seed: 0

  last_only: 0

  exp_name: test
  verbose: 0
  profile: 0

