





get_ipython().getoutput("pip install -q transformers diffusers torch pydub TTS openai-whisper accelerate numba --break-system-packages")


import torch
from transformers import pipeline, GPT2LMHeadModel, GPT2Tokenizer
from transformers import MarianMTModel, MarianTokenizer
from diffusers import StableDiffusionPipeline
from IPython.display import Audio, display
import numpy as np
from TTS.api import TTS
import whisper

USE_CUDA = True
device = "cuda" if USE_CUDA and torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")





def generate_text(prompt, max_length=50):
    model_name = "gpt2-medium"
    model = GPT2LMHeadModel.from_pretrained(model_name).to(device)
    tokenizer = GPT2Tokenizer.from_pretrained(model_name)
    
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(inputs["input_ids"], max_length=max_length, num_return_sequences=1)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Test the function
prompt = "Once upon a time in a land far, far away"
generated_text = generate_text(prompt)
print("Generated Text:")
print(generated_text)





# Your code here
creative_prompt = "The robot woke up and realized it had emotions"
story = generate_text(creative_prompt, max_length=100)
print(story)

# Your analysis here
# ...






def translate_text(text, src_lang="en", tgt_lang="fr"):
    model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
    model = MarianMTModel.from_pretrained(model_name).to(device)
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    
    inputs = tokenizer(text, return_tensors="pt", padding=True).to(device)
    translated = model.generate(**inputs)
    return tokenizer.decode(translated[0], skip_special_tokens=True)

# Test the function
text_to_translate = "Hello, how are you?"
translated_text = translate_text(text_to_translate)
print(f"Original: {text_to_translate}")
print(f"Translated: {translated_text}")





# Your code here
original_sentence = "The quick brown fox jumps over the lazy dog"
languages = ["fr", "de", "es"]

for lang in languages:
    translated = translate_text(original_sentence, "en", lang)
    back_translated = translate_text(translated, lang, "en")
    print(f"{lang.upper()}: {translated}")
    print(f"Back to English: {back_translated}\n")

# Your analysis here
# ...






def generate_image(prompt, output_path="generated_image.png"):
    model_id = "runwayml/stable-diffusion-v1-5"
    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(device)
    
    image = pipe(prompt, num_inference_steps=50, guidance_scale=7.5).images[0]
    image.save(output_path)
    display(image)

# Test the function
image_prompt = "A futuristic city with flying cars"
generate_image(image_prompt)





# Your code here
prompts = [
    "A steampunk-inspired coffee machine",
    "An underwater library with merfolk readers",
    "A treehouse skyscraper in a futuristic forest"
]

for i, prompt in enumerate(prompts):
    print(f"Prompt {i+1}: {prompt}")
    generate_image(prompt, f"image_{i+1}.png")
    print("\n")

# Your analysis here
# ...






def generate_audio(text, output_path="output.wav"):
    tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC", progress_bar=True, gpu=USE_CUDA)
    tts.tts_to_file(text=text, file_path=output_path)
    display(Audio(output_path))

def transcribe_audio(file_path):
    model = whisper.load_model("base")
    result = model.transcribe(file_path)
    return result["text"]

# Test the functions
text_to_speak = "Hello, this is a test of text-to-speech conversion."
generate_audio(text_to_speak)

transcribed_text = transcribe_audio("output.wav")
print("Transcribed Text:")
print(transcribed_text)





# Your code here
original_prompt = "The future of artificial intelligence is"
generated_text = generate_text(original_prompt, max_length=50)
print("Original Generated Text:")
print(generated_text)

generate_audio(generated_text, "chain_output.wav")

transcribed_text = transcribe_audio("chain_output.wav")
print("\nTranscribed Text:")
print(transcribed_text)

# Your analysis here
# ...




